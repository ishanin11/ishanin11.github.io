---
layout: post
title: "Neural Network"
date: 2024-07-07
---

## Neural Networks


Neural Networks

I briefly remember being introduced to this topic about 3 years ago when I started my master’s in Human Computer Interaction. As and how time progresses, there have been instances where I’ve been compelled to learn, integrate and apply this concept in greater capacity. 

What is neural networks to begin with?
As the name suggests, neural has a stark resonance with neurons, and network with connections. Where is this example found again? The human brain.

In short, neural networks simulate the experience of identifying, analyzing and suggesting patterns similar to how our brains works, the only difference being, the input is data.  
On diving into this concept further, the key components would essentially be,
- Neurons
    - Each neuron receives and input, processes them and produces and output.
- Layers
    - Input, hidden and output layer which in-turn acts on various layers of the network.
- Weight
    - The connections between every layer which is adjusted during trainin to minimize the error in the network’s output.
- Activation function
    - Determines the output of a neuron depending on the no. or set of inputs. Common activation functions include, Sigmoid, Tahn, and ReLU.

If I had to go about simplifying the process of how how it works, the first step would be to outline the broader categories of,
1. Artificial Intelligence: the simulation of human intelligence processes by machines, especially computer systems. Specific applications of AI include expert systems, natural language processing, speech recognition and machine vision.
2. Machine Learning: A branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.
3. Deep Learning: Deep learning is a subset of machine learning, which is essentially a neural network with three or more layers. These neural networks attempt to simulate the behavior of the human brain—albeit far from matching its ability—allowing it to “learn” from large amounts of data.

The next step is to understand how neural networks work,
- Initialization 
- Forward propagation: As the data is passed through the network layers, each neuron processes the input, applies the activation function and passes the results to the next layer.
- Loss Function: The difference between what the actual output and predicted output is 

